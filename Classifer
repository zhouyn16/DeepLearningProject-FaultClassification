#导入
from keras.models import Sequential
from keras.utils import np_utils
from keras.callbacks import ReduceLROnPlateau
from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D
from keras.optimizers import RMSprop
from keras.models import Model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

###预定义
train_each=80
test_each=1000

###重复取样
repeat=60
###

###mixup次数
mixup_num=3
###

###高斯噪音方差
var=0.01
gauss_num=1
###

def preprocess(table):
    post_table=(table-np.mean(table))/np.std(table)
    return post_table

def evaluate(X_pred_label,y_test_label):
    end=pd.DataFrame(columns=['recall','precision','F_score'])
    for i in range(10):
        TP=np.sum(np.array(X_pred_label==i)*np.array(y_test_label==i))
        FP=np.sum(np.array(X_pred_label==i)*np.array(y_test_label!=i))
        FN=np.sum(np.array(X_pred_label!=i)*np.array(y_test_label==i))
        precise=TP/(TP+FP)
        recall=TP/(TP+FN)
        end.loc[i]=np.array([recall,precise,2*precise*recall/(precise+recall)])
    return end
    
def ROC_curve():
    for i in range(10):
        denf_layer_model = Model(inputs=dl.input,outputs=dl.get_layer('denf').output)
        y_score=denf_layer_model.predict(X_test)[:,i]
        fpr, tpr, thresholds = metrics.roc_curve(1*(np.argmax(y_test, axis=1)==i),y_score)
        roc_auc=metrics.auc(fpr, tpr)
        plt.clf()
        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.0])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.legend(loc="lower right")
        plt.savefig('%d_ROC.png'%i)
        plt.show()
   
#数据导入与合并
try:
    data_train=pd.read_csv('数据/repeat%dtrain.csv'%repeat,index_col=0,engine='python')
    data_test=pd.read_csv('数据/repeat%dtest.csv'%repeat,index_col=0,engine='python')
except:
    columns_repeat=['kind']
    for re in range(1,repeat+1):
        columns_repeat+=['De%d'%re,'Fe%d'%re,'Ba%d'%re]
    data_train=pd.DataFrame(columns=columns_repeat)
    data_test=pd.DataFrame(columns=columns_repeat)
    print('数据导入：',end=' ')
    for i in range(10):
        data_read_train=pd.read_csv('数据/%dtrain.csv'%i,index_col=0,engine='python')
        data_read_test=pd.read_csv('数据/%dtest.csv'%i,index_col=0,engine='python')

        ###NA填充0
        if i==0:
            data_read_train.insert(2,'Ba',0)
            data_read_test.insert(2,'Ba',0)
        ###

        ###重复取样
        data_read_train_repeat=data_read_train.copy()
        long=data_read_train.shape[0]
        for re in range(1,repeat):
            data_read_train_repeat=pd.concat([data_read_train_repeat.iloc[0:long,:],data_read_train.iloc[re:long,:].reset_index(drop=1)],axis=1)
        data_read_train=data_read_train_repeat.iloc[0:long-repeat+1]
        data_read_test_repeat=data_read_test.copy()
        long=data_read_test.shape[0]
        for re in range(1,repeat):
            data_read_test_repeat=pd.concat([data_read_test_repeat.iloc[0:long,:],data_read_test.iloc[re:long,:].reset_index(drop=1)],axis=1)
        data_read_test=data_read_test_repeat.iloc[0:long-repeat+1]
        ###

        data_read_train.insert(0,'kind',i)
        data_read_test.insert(0,'kind',i)
        data_read_train.columns=columns_repeat
        data_read_test.columns=columns_repeat
        data_train=pd.concat([data_train,data_read_train.iloc[200:train_each+200,:]])
        data_test=pd.concat([data_test,data_read_test.iloc[200:test_each+200,:]])
        print((i+1)/10,end=' ')
    data_train.to_csv('数据/repeat%dtrain.csv'%repeat)
    data_test.to_csv('数据/repeat%dtest.csv'%repeat)

###训练集与测试集
data_train=data_train[data_train.kind!=0]
data_test=data_test[data_test.kind!=0]
data_train=data_train.sample(frac=1.0).reset_index(drop=True)
X_train=preprocess(data_train.iloc[:,1:])
X_test=preprocess(data_test.iloc[:,1:])
y_train=np_utils.to_categorical(data_train.iloc[:,0])
y_test=np_utils.to_categorical(data_test.iloc[:,0])

###mixup
X_train_mixup_result=X_train
y_train_mixup_result=y_train
for i in range(mixup_num):
    beta=np.random.beta(1,1,X_train.shape[0]).reshape(X_train.shape[0],1)
    data_train_mixup=data_train.sample(frac=1.0).reset_index(drop=True)
    X_train_mixup=preprocess(data_train_mixup.iloc[:,1:])
    y_train_mixup=np_utils.to_categorical(data_train_mixup.iloc[:,0])
    X_train_mixup=beta*X_train_mixup+(1-beta)*X_train
    y_train_mixup=beta*y_train_mixup+(1-beta)*y_train
    X_train_mixup_result=pd.concat([X_train_mixup_result,X_train_mixup])
    y_train_mixup_result=np.vstack([y_train_mixup_result,y_train_mixup])
X_train=X_train_mixup_result
y_train=y_train_mixup_result
###

###高斯噪音
X_train_gauss_result=X_train
y_train_gauss_result=y_train
for i in range(gauss_num):
    gauss=np.random.normal(0,var,[X_train.shape[0],X_train.shape[1]])
    X_train_gauss=gauss+X_train
    X_train_gauss_result=pd.concat([X_train_gauss_result,X_train_gauss])
    y_train_gauss_result=np.vstack([y_train_gauss_result,y_train])
X_train=X_train_gauss_result
y_train=y_train_gauss_result
###

###卷积网络
X_train=X_train.values.reshape(-1,repeat,3,1).transpose(0,3,1,2)
X_test=X_test.values.reshape(-1,repeat,3,1).transpose(0,3,1,2)
###

###学习率调整
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)
###

dl=Sequential()

###卷积网络
dl.add(Conv2D(filters=32, kernel_size=(1,10), padding='Valid', activation='relu',input_shape=(1,repeat,3),name="conv1"))
dl.add(MaxPool2D(pool_size=(1,4), strides=(1,1),name="pool1"))
dl.add(Dropout(0.75))
dl.add(Flatten())
dl.add(Dense(units=500, activation="relu", kernel_initializer="normal",name="den1"))
dl.add(Dropout(0.75))
###

# ###非卷积网络
# dl.add(Dense(units=500, input_dim=3*repeat, activation="relu", kernel_initializer="normal"))
# dl.add(Dropout(0.25))
# dl.add(Dense(units=500, activation="relu", kernel_initializer="normal"))
# dl.add(Dropout(0.25))
# ###

# dl.add(Dense(units=40, activation="relu", kernel_initializer="normal",name="den2"))
# dl.add(Dropout(0.5))

dl.add(Dense(units=10, activation="softmax", kernel_initializer="normal",name="denf"))
dl.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
dl.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=800,verbose=2,callbacks=[learning_rate_reduction])

print(dl.summary())

pd.crosstab(data_test.iloc[:,0],dl.predict_classes(X_test),rownames=['label'],colnames=['predict'])
evaluate(dl.predict_classes(X_test),data_test.iloc[:,0])
ROC_curve()
