#导入
from keras.models import Sequential
from keras.utils import np_utils
from keras.callbacks import ReduceLROnPlateau
from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D,LSTM
from keras.optimizers import RMSprop
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

###预定义
train_each=80
test_each=1000

###重复取样
repeat=60
###

###mixup次数
mixup_num=3
###

###高斯噪音方差
var=0.01
gauss_num=1
###

def preprocess(table):
    post_table=(table-np.mean(table))/np.std(table)
    return post_table
   
#数据导入与合并
try:
    data_train=pd.read_csv('数据/repeat%dtrain.csv'%repeat,index_col=0,engine='python')
    data_test=pd.read_csv('数据/repeat%dtest.csv'%repeat,index_col=0,engine='python')
except:
    columns_repeat=['kind']
    for re in range(1,repeat+1):
        columns_repeat+=['De%d'%re,'Fe%d'%re,'Ba%d'%re]
    data_train=pd.DataFrame(columns=columns_repeat)
    data_test=pd.DataFrame(columns=columns_repeat)
    print('数据导入：',end=' ')
    for i in range(10):
        data_read_train=pd.read_csv('数据/%dtrain.csv'%i,index_col=0,engine='python')
        data_read_test=pd.read_csv('数据/%dtest.csv'%i,index_col=0,engine='python')

        ###NA填充0
        if i==0:
            data_read_train.insert(2,'Ba',0)
            data_read_test.insert(2,'Ba',0)
        ###

        ###重复取样
        data_read_train_repeat=data_read_train.copy()
        long=data_read_train.shape[0]
        for re in range(1,repeat):
            data_read_train_repeat=pd.concat([data_read_train_repeat.iloc[0:long,:],data_read_train.iloc[re:long,:].reset_index(drop=1)],axis=1)
        data_read_train=data_read_train_repeat.iloc[0:long-repeat+1]
        data_read_test_repeat=data_read_test.copy()
        long=data_read_test.shape[0]
        for re in range(1,repeat):
            data_read_test_repeat=pd.concat([data_read_test_repeat.iloc[0:long,:],data_read_test.iloc[re:long,:].reset_index(drop=1)],axis=1)
        data_read_test=data_read_test_repeat.iloc[0:long-repeat+1]
        ###

        data_read_train.insert(0,'kind',i)
        data_read_test.insert(0,'kind',i)
        data_read_train.columns=columns_repeat
        data_read_test.columns=columns_repeat
        data_train=pd.concat([data_train,data_read_train.iloc[200:train_each+200,:]])
        data_test=pd.concat([data_test,data_read_test.iloc[200:test_each+200,:]])
        print((i+1)/10,end=' ')
    data_train.to_csv('数据/repeat%dtrain.csv'%repeat)
    data_test.to_csv('数据/repeat%dtest.csv'%repeat)

###训练集与测试集
data_train=data_train[data_train.kind!=0]
data_test=data_test[data_test.kind!=0]
data_train=data_train.sample(frac=1.0).reset_index(drop=True)
X_train=preprocess(data_train.iloc[:,1:])
X_test=preprocess(data_test.iloc[:,1:])
y_train=np_utils.to_categorical(data_train.iloc[:,0])
y_test=np_utils.to_categorical(data_test.iloc[:,0])

###mixup
X_train_mixup_result=X_train
y_train_mixup_result=y_train
for i in range(mixup_num):
    beta=np.random.beta(1,1,X_train.shape[0]).reshape(X_train.shape[0],1)
    data_train_mixup=data_train.sample(frac=1.0).reset_index(drop=True)
    X_train_mixup=preprocess(data_train_mixup.iloc[:,1:])
    y_train_mixup=np_utils.to_categorical(data_train_mixup.iloc[:,0])
    X_train_mixup=beta*X_train_mixup+(1-beta)*X_train
    y_train_mixup=beta*y_train_mixup+(1-beta)*y_train
    X_train_mixup_result=pd.concat([X_train_mixup_result,X_train_mixup])
    y_train_mixup_result=np.vstack([y_train_mixup_result,y_train_mixup])
X_train=X_train_mixup_result
y_train=y_train_mixup_result
###

###高斯噪音
X_train_gauss_result=X_train
y_train_gauss_result=y_train
for i in range(gauss_num):
    gauss=np.random.normal(0,var,[X_train.shape[0],X_train.shape[1]])
    X_train_gauss=gauss+X_train
    X_train_gauss_result=pd.concat([X_train_gauss_result,X_train_gauss])
    y_train_gauss_result=np.vstack([y_train_gauss_result,y_train])
X_train=X_train_gauss_result
y_train=y_train_gauss_result
###

# ###卷积网络
# X_train=X_train.values.reshape(-1,repeat,3,1).transpose(0,3,1,2)
# X_test=X_test.values.reshape(-1,repeat,3,1).transpose(0,3,1,2)
# ###

###时序网络
X_train=X_train.values.reshape(-1,repeat,3)
X_test=X_test.values.reshape(-1,repeat,3)
# print(X_train.shape)
###

###学习率调整
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)
###

dl=Sequential()

##时序网络
dl.add(LSTM(units=64, input_shape=(repeat,3),activation='relu',return_sequences=True))
dl.add(Flatten())
dl.add(Dropout(0.5))
dl.add(Dense(units=500, activation="relu", kernel_initializer="normal",name="den1"))
dl.add(Dropout(0.5))
###

# ###非卷积网络
# dl.add(Dense(units=500, input_dim=3*repeat, activation="relu", kernel_initializer="normal"))
# dl.add(Dropout(0.25))
# dl.add(Dense(units=500, activation="relu", kernel_initializer="normal"))
# dl.add(Dropout(0.25))
# ###

# dl.add(Dense(units=500, activation="relu", kernel_initializer="normal",name="den2"))
# dl.add(Dropout(0.5))

dl.add(Dense(units=10, activation="softmax", kernel_initializer="normal",name="den3"))
dl.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
dl.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=800,verbose=2,callbacks=[learning_rate_reduction])

print(dl.summary())

pd.crosstab(data_test.iloc[:,0],dl.predict_classes(X_test),rownames=['label'],colnames=['predict'])

