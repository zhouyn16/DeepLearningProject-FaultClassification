#导入
from keras.models import Sequential
from keras.utils import np_utils
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D
from keras.optimizers import RMSprop
from keras.models import Model
from sklearn import metrics
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random as rd

###预定义
train_each=1000
test_each=1000

###重复取样
repeat=60
###

###mixup次数
mixup_num=3
###

###高斯噪音方差
var=0.01
gauss_num=1
###

###随机数
randomint=rd.randint(0,15000)
###

def preprocess(table):
    post_table=table.values.astype('float32')
    post_table=(post_table-np.mean(post_table,axis=1).reshape(-1,1))/np.std(post_table,axis=1).reshape(-1,1)
    post_table=pd.DataFrame(post_table,columns=table.columns)
    return post_table

def evaluate(X_pred_label,y_test_label):
    end=pd.DataFrame(columns=['recall','precision','F_score'])
    for i in range(10):
        TP=np.sum(np.array(X_pred_label==i)*np.array(y_test_label==i))
        FP=np.sum(np.array(X_pred_label==i)*np.array(y_test_label!=i))
        FN=np.sum(np.array(X_pred_label!=i)*np.array(y_test_label==i))
        precise=TP/(TP+FP)
        recall=TP/(TP+FN)
        end.loc[i]=np.array([recall,precise,2*precise*recall/(precise+recall)])
    return end
    
def ROC_curve(name,y,y_score):
    fpr, tpr, thresholds = metrics.roc_curve(y,y_score)
    roc_auc=metrics.auc(fpr, tpr)
    plt.clf()
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.0])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")
    plt.savefig('%s_ROC.png'%name)
    plt.show()
        
###数据导入与合并
try:
    data_train=pd.read_csv('数据/repeat%dtrain.csv'%repeat,index_col=0,engine='python')
    data_test=pd.read_csv('数据/repeat%dtest.csv'%repeat,index_col=0,engine='python')
except:
    columns_repeat=['kind']
    for re in range(1,repeat+1):
        columns_repeat+=['De%d'%re,'Fe%d'%re,'Ba%d'%re]+['De%dstd'%re,'Fe%dstd'%re,'Ba%dstd'%re]
    data_train=pd.DataFrame(columns=columns_repeat)
    data_test=pd.DataFrame(columns=columns_repeat)
    print('数据导入：',end=' ')
    for i in range(10):
        data_read_train=pd.read_csv('数据/%dtrain.csv'%i,index_col=0,engine='python')
        data_read_test=pd.read_csv('数据/%dtest.csv'%i,index_col=0,engine='python')

        ###NA填充0
        if i==0:
            data_read_train.insert(2,'Ba',0)
            data_read_test.insert(2,'Ba',0)
        ###
        
        ###填充std
        data_read_train.insert(3,'De%dstd'%re,np.std(data_read_train.iloc[:,0]))
        data_read_test.insert(3,'De%dstd'%re,np.std(data_read_test.iloc[:,0]))
        data_read_train.insert(4,'Fe%dstd'%re,np.std(data_read_train.iloc[:,1]))
        data_read_test.insert(4,'Fe%dstd'%re,np.std(data_read_test.iloc[:,1]))
        data_read_train.insert(5,'Ba%dstd'%re,np.std(data_read_train.iloc[:,2]))
        data_read_test.insert(5,'Ba%dstd'%re,np.std(data_read_test.iloc[:,2]))
        ###

        ###重复取样
        data_read_train_repeat=data_read_train.copy()
        long=data_read_train.shape[0]
        for re in range(1,repeat):
            data_read_train_repeat=pd.concat([data_read_train_repeat.iloc[0:long,:],data_read_train.iloc[re:long,:].reset_index(drop=1)],axis=1)
        data_read_train=data_read_train_repeat.iloc[0:long-repeat+1]
        data_read_test_repeat=data_read_test.copy()
        long=data_read_test.shape[0]
        for re in range(1,repeat):
            data_read_test_repeat=pd.concat([data_read_test_repeat.iloc[0:long,:],data_read_test.iloc[re:long,:].reset_index(drop=1)],axis=1)
        data_read_test=data_read_test_repeat.iloc[0:long-repeat+1]
        ###

        data_read_train.insert(0,'kind',i)
        data_read_test.insert(0,'kind',i)
        data_read_train.columns=columns_repeat
        data_read_test.columns=columns_repeat
        data_train=pd.concat([data_train,data_read_train.iloc[randomint:train_each+randomint,:]])
        data_test=pd.concat([data_test,data_read_test.iloc[randomint:test_each+randomint,:]])
        print((i+1)/10,end=' ')
#     data_train.to_csv('数据/repeat%dtrain.csv'%repeat)
#     data_test.to_csv('数据/repeat%dtest.csv'%repeat)

###训练集与测试集
X_train=preprocess(data_train.iloc[:,1:])[(data_train.kind!=0).reset_index(drop=True)].reset_index(drop=True)
X_test=preprocess(data_test.iloc[:,1:])[(data_test.kind!=0).reset_index(drop=True)].reset_index(drop=True)
X_test_0in=data_test.iloc[:,1:]
y_train=np_utils.to_categorical(data_train.iloc[:,0]-1)[data_train.kind!=0]
y_test=np_utils.to_categorical(data_test.iloc[:,0]-1)[data_test.kind!=0]
y_test_0in=np_utils.to_categorical(data_test.iloc[:,0])

###mixup
X_train_mixup_result=X_train
y_train_mixup_result=y_train
for i in range(mixup_num):
    beta=np.random.beta(1,1,X_train.shape[0]).reshape(X_train.shape[0],1)
    data_train_mixup=data_train[data_train.kind!=0].sample(frac=1.0).reset_index(drop=True)
    X_train_mixup=preprocess(data_train_mixup.iloc[:,1:])
    y_train_mixup=np_utils.to_categorical(data_train_mixup.iloc[:,0]-1)
    X_train_mixup=beta*X_train_mixup+(1-beta)*X_train
    y_train_mixup=beta*y_train_mixup+(1-beta)*y_train
    X_train_mixup_result=pd.concat([X_train_mixup_result,X_train_mixup])
    y_train_mixup_result=np.vstack([y_train_mixup_result,y_train_mixup])
X_train=X_train_mixup_result
y_train=y_train_mixup_result
###

###高斯噪音
X_train_gauss_result=X_train
y_train_gauss_result=y_train
for i in range(gauss_num):
    gauss=np.random.normal(0,var,[X_train.shape[0],X_train.shape[1]])
    X_train_gauss=gauss+X_train
    X_train_gauss_result=pd.concat([X_train_gauss_result,X_train_gauss])
    y_train_gauss_result=np.vstack([y_train_gauss_result,y_train])
X_train=X_train_gauss_result
y_train=y_train_gauss_result
###

###卷积网络
X_train=X_train.values.reshape(-1,repeat,6,1).transpose(0,3,1,2)
X_test=X_test.values.reshape(-1,repeat,6,1).transpose(0,3,1,2)
###

###学习率调整/提前终止
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)
EarlyStop=EarlyStopping(monitor='val_loss', patience=5)
###

dl=Sequential()

###卷积网络
dl.add(Conv2D(filters=32, kernel_size=(1,10), padding='Valid', activation='relu',input_shape=(1,repeat,6)))
dl.add(MaxPool2D(pool_size=(1,4), strides=(1,1)))
dl.add(Dropout(0.5))
dl.add(Flatten())
dl.add(Dense(units=128, activation="relu", kernel_initializer="normal"))
dl.add(Dropout(0.5))
###

dl.add(Dense(units=9, activation="softmax", kernel_initializer="normal",name="denf"))
dl.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
dl.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=800,verbose=2,callbacks=[EarlyStop])

###先验
predict_0=[]
score_0=[]
X_test_0in_this=X_test_0in.values.reshape(-1,repeat,6).transpose(0,2,1)
for idx in range(len(X_test_0in)):
    list_0=[X_test_0in_this[idx][0][a+1]-X_test_0in_this[idx][0][a] for a in range(len(X_test_0in_this[idx][0])-1)]
    list_0_1=[list_0[a+1]-list_0[a] for a in range(len(list_0)-1)]
    if np.var(list_0_1)*100<0.3:##0.1--0.5
        predict_0.append(0)
        score_0.append(0.3-np.var(list_0_1)*100)
        continue
    predict_0.append(1)
    score_0.append(0)
predict_0=np.array(predict_0)
score_0=np.array(score_0)
###

###网络预测与分数
X_test_0in_this=preprocess(X_test_0in).values.reshape(-1,repeat,6,1).transpose(0,3,1,2)
denf_layer_model = Model(inputs=dl.input,outputs=dl.get_layer('denf').output)
score_other=denf_layer_model.predict(X_test_0in_this)
###

###预测与分数合并
predict_all=predict_0*(dl.predict_classes(X_test_0in_this)+1)
score_all=np.hstack([score_0.reshape(-1,1),score_other])
###



print(dl.summary())

print(pd.crosstab(data_test.iloc[:,0],predict_all,rownames=['label'],colnames=['predict']))
print(evaluate(predict_all,data_test.iloc[:,0]))
denf_layer_model = Model(inputs=dl.input,outputs=dl.get_layer('denf').output)
for i in range(10):
    ROC_curve('%d'%i,1*(data_test.kind==i),score_all[:,i])
