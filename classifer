###卷积网络
X_train=X_train.values.reshape(-1,repeat,6,1).transpose(0,3,1,2)
X_test=X_test.values.reshape(-1,repeat,6,1).transpose(0,3,1,2)
###

###学习率调整/提前终止
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)
EarlyStop=EarlyStopping(monitor='val_loss', patience=5)
###

dl=Sequential()

###卷积网络
dl.add(Conv2D(filters=32, kernel_size=(1,10), padding='Valid', activation='relu',input_shape=(1,repeat,6)))
dl.add(MaxPool2D(pool_size=(1,4), strides=(1,1)))
dl.add(Dropout(0.5))
dl.add(Flatten())
dl.add(Dense(units=128, activation="relu", kernel_initializer="normal"))
dl.add(Dropout(0.5))
###

dl.add(Dense(units=9, activation="softmax", kernel_initializer="normal",name="denf"))
dl.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
dl.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=800,verbose=2,callbacks=[EarlyStop])

###先验
predict_0=[]
score_0=[]
X_test_0in_this=X_test_0in.values.reshape(-1,repeat,6).transpose(0,2,1)
for idx in range(len(X_test_0in)):
    list_0=[X_test_0in_this[idx][0][a+1]-X_test_0in_this[idx][0][a] for a in range(len(X_test_0in_this[idx][0])-1)]
    list_0_1=[list_0[a+1]-list_0[a] for a in range(len(list_0)-1)]
    if np.var(list_0_1)*100<0.3:##0.1--0.5
        predict_0.append(0)
        score_0.append(0.3-np.var(list_0_1)*100)
        continue
    predict_0.append(1)
    score_0.append(0)
predict_0=np.array(predict_0)
score_0=np.array(score_0)
###

###网络预测与分数
X_test_0in_this=preprocess(X_test_0in).values.reshape(-1,repeat,6,1).transpose(0,3,1,2)
denf_layer_model = Model(inputs=dl.input,outputs=dl.get_layer('denf').output)
score_other=denf_layer_model.predict(X_test_0in_this)
###

###预测与分数合并
predict_all=predict_0*(dl.predict_classes(X_test_0in_this)+1)
score_all=np.hstack([score_0.reshape(-1,1),score_other])
###

print(dl.summary())
